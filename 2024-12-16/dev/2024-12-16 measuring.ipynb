{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the structures\n",
    "2024-12-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pymol import cmd\n",
    "from Bio.PDB import PDBParser, ShrakeRupley\n",
    "from Bio.PDB.PDBExceptions import PDBConstructionException\n",
    "from chempy import cpv\n",
    "import numpy as np\n",
    "import biotite.structure as struc\n",
    "import biotite.structure.io.pdb as pdb\n",
    "import biotite.structure.bonds as bonds\n",
    "\n",
    "structure_basePath = pathlib.Path(r'.\\AF_DMI_structures\\AF_DMI_structures')\n",
    "structure_folders = ['AF_DMI_structures1', 'AF_DMI_structures2', 'AF_DMI_structures3']\n",
    "structure_folders = ['AF_DMI_structures1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "\n",
    "structures_count = 0\n",
    "pdb_structures_path = {}\n",
    "\n",
    "for folder in structure_folders:\n",
    "    folder_path = pathlib.Path.absolute(structure_basePath / folder)\n",
    "    if not folder_path.is_dir():\n",
    "        print(f\"\\tERROR: {folder_path} is not a folder\")\n",
    "        continue\n",
    "    pdb_structures_path[folder] = {}\n",
    "    for prediction_path in folder_path.iterdir():\n",
    "        if not prediction_path.is_dir():\n",
    "            continue\n",
    "        structure_name = prediction_path.stem\n",
    "        pdb_structures_path[folder][structure_name] = {}\n",
    "        for pdb_file in prediction_path.iterdir():\n",
    "            if not str(pdb_file).endswith(\".pdb\"):\n",
    "                continue\n",
    "            structures_count+=1\n",
    "            pdb_structures_path[folder][structure_name][pdb_file.stem] = pdb_file\n",
    "print(f\"Found {structures_count} structures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files into structure objects\n",
    "\n",
    "pdb_structures = {}\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "for folder, structureDict in pdb_structures_path.items():\n",
    "    pdb_structures[folder] = {}\n",
    "    print(f\"Reading in folder {folder}\")\n",
    "    for structure_name, fileArray in structureDict.items():\n",
    "        pdb_structures[folder][structure_name] = {}\n",
    "        for file_name, path in fileArray.items():\n",
    "            try:\n",
    "                structure = parser.get_structure(\"structure\", file=path)\n",
    "            except PDBConstructionException:\n",
    "                print(f\"Can't parse structure {structure_name} (file {path.stem})\")\n",
    "                continue\n",
    "            except ValueError as ex:\n",
    "                print(f\"Can't parse structure {structure_name} (file {path.stem}) due to the following reason: {ex}\")\n",
    "                continue\n",
    "            chains = [c for c in structure.get_chains()]\n",
    "            if len(chains) != 2:\n",
    "                print(f\"Can't parse structure {structure_name} (file {path.stem}) because it has not 2 chains\")\n",
    "                continue\n",
    "            structure_biotite = pdb.get_structure(pdb.PDBFile.read(path))\n",
    "            pdb_structures[folder][structure_name][file_name] = [structure, structure_biotite]\n",
    "print(\"---Finished---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells for calculations of the interactions\n",
    "\n",
    "# Hydrophobic residues including Glycine (GLY) and Proline (PRO)\n",
    "hydrophobic_residues = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'PRO', 'TRP', 'GLY'}\n",
    "\n",
    "# Function to calculate buried area using Shrake-Rupley\n",
    "def calculate_buried_area(structure):\n",
    "    chains = [c for c in structure.get_chains()]\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    # Calculate SASA for the whole structure\n",
    "    sasa = ShrakeRupley()\n",
    "    sasa.compute(structure, level=\"A\")\n",
    "    total_area = sum(atom.sasa for atom in structure.get_atoms())\n",
    "\n",
    "    # Calculate buried area for each chain separately\n",
    "    chain1 = structure[0][chains[0].id]\n",
    "    chain2 = structure[0][chains[1].id]\n",
    "    \n",
    "    sasa.compute(chain1, level=\"A\")\n",
    "    area_ch1 = sum(atom.sasa for atom in chain1.get_atoms())\n",
    "    \n",
    "    sasa.compute(chain2, level=\"A\")\n",
    "    area_ch2 = sum(atom.sasa for atom in chain2.get_atoms())\n",
    "\n",
    "    # Calculate buried area\n",
    "    buried_area = (area_ch1 + area_ch2 - total_area)\n",
    "    return round(buried_area, 3)\n",
    " \n",
    "# Function to calculate the minimum distance of interface residues\n",
    "def minimum_interface_distance(structure):\n",
    "    chains = [c for c in structure.get_chains()]\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    chain1 = structure[0][chains[0].id]\n",
    "    chain2 = structure[0][chains[1].id]\n",
    "\n",
    "    min_distance = float('inf')  # Initialize with a large number\n",
    "\n",
    "    atomsCA_chain1 = [a for a in chain1.get_atoms() if a.get_name() == \"CA\"]\n",
    "    atomsCA_chain2 = [a for a in chain2.get_atoms() if a.get_name() == \"CA\"]\n",
    "\n",
    "    for atom1 in atomsCA_chain1:\n",
    "        for atom2 in atomsCA_chain2:\n",
    "            min_distance = min(min_distance, cpv.distance(atom1.coord, atom2.coord))\n",
    "\n",
    "    # If no distances were found, return 0, otherwise return the minimum distance\n",
    "    return min_distance if min_distance != float('inf') else 0\n",
    "\n",
    "\n",
    "# Function to calculate hydrogen bonds using Biotite's Baker-Hubbard algorithm\n",
    "def find_h_bonds(structure, structure_biotite):\n",
    "    chains = [c for c in structure.get_chains()]\n",
    "    assert len(chains) == 2\n",
    "    \n",
    "    # If the structure contains only a single model, convert AtomArrayStack to AtomArray\n",
    "    if structure_biotite.stack_depth() == 1:\n",
    "        atom_array = structure_biotite[0]\n",
    "    else:\n",
    "        raise ValueError(\"The provided structure contains multiple models. Please provide a structure with a single model.\")\n",
    "    \n",
    "    # Generate a BondList using a distance-based approach\n",
    "    bond_list = bonds.connect_via_distances(atom_array)\n",
    "\n",
    "    # Assign the generated BondList to the atom array\n",
    "    atom_array.bonds = bond_list\n",
    "\n",
    "    # Create selection masks for the two chains\n",
    "    selection1 = atom_array.chain_id == chains[0].id\n",
    "    selection2 = atom_array.chain_id == chains[1].id\n",
    "    \n",
    "    # Calculate hydrogen bonds between the two chains\n",
    "    try:\n",
    "        triplets = struc.hbond(atom_array, selection1=selection1, selection2=selection2)\n",
    "        if isinstance(triplets, tuple):\n",
    "            triplets = triplets[0]  # Extract the first item if it's a tuple\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating hydrogen bonds: {e}\")\n",
    "        return 0\n",
    "\n",
    "    return len(triplets)\n",
    "\n",
    "# Function to calculate salt bridges using BioPython\n",
    "def find_salt_bridges_biopython(structure, cutoff=4.0):\n",
    "    chains = [c for c in structure.get_chains()]\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    chain1 = structure[0][chains[0].id]\n",
    "    chain2 = structure[0][chains[1].id]\n",
    "\n",
    "    acidic_residues = {'ASP': ['OD1', 'OD2'], 'GLU': ['OE1', 'OE2']}\n",
    "    basic_residues = {'ARG': ['NH1', 'NH2', 'NE'], 'LYS': ['NZ']}\n",
    "\n",
    "    salt_bridges = 0\n",
    "\n",
    "    for res1 in chain1:\n",
    "        if res1.resname in acidic_residues:\n",
    "            for atom_name1 in acidic_residues[res1.resname]:\n",
    "                if atom_name1 in res1:\n",
    "                    atom1 = res1[atom_name1]\n",
    "                    for res2 in chain2:\n",
    "                        if res2.resname in basic_residues:\n",
    "                            for atom_name2 in basic_residues[res2.resname]:\n",
    "                                if atom_name2 in res2:\n",
    "                                    atom2 = res2[atom_name2]\n",
    "                                    distance = atom1 - atom2\n",
    "                                    if distance <= cutoff:\n",
    "                                        salt_bridges += 1\n",
    "\n",
    "    return salt_bridges\n",
    "\n",
    "# Function to calculate hydrophobic interactions considering only carbon atoms\n",
    "def find_hydrophobic_interactions(structure, cutoff=5.0):\n",
    "    chains = [c for c in structure.get_chains()]\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    # Get the chains\n",
    "    chain1 = structure[0][chains[0].id]\n",
    "    chain2 = structure[0][chains[1].id]\n",
    "\n",
    "    hydrophobic_interactions = 0\n",
    "\n",
    "    # Compare each hydrophobic residue in chain1 with each hydrophobic residue in chain2\n",
    "    for res1 in chain1:\n",
    "        if res1.resname in hydrophobic_residues:\n",
    "            for atom1 in res1:\n",
    "                if atom1.element == 'C':  # Only consider carbon atoms\n",
    "                    for res2 in chain2:\n",
    "                        if res2.resname in hydrophobic_residues:\n",
    "                            for atom2 in res2:\n",
    "                                if atom2.element == 'C':  # Only consider carbon atoms\n",
    "                                    distance = atom1 - atom2\n",
    "                                    if distance <= cutoff:\n",
    "                                        hydrophobic_interactions += 1\n",
    "\n",
    "    return hydrophobic_interactions\n",
    "\n",
    "def evaluate_structure(structure_name, file_name, structure):\n",
    "    buried_area = calculate_buried_area(structure[0])\n",
    "    hbonds = find_h_bonds(structure[0], structure[1])\n",
    "    min_distance = minimum_interface_distance(structure[0])\n",
    "    salt_bridges = find_salt_bridges_biopython(structure[0])\n",
    "    hydrophobic_interactions = find_hydrophobic_interactions(structure[0])\n",
    "    return {\n",
    "        'prediction_name': structure_name,\n",
    "        'structure_file': file_name,\n",
    "        'hbonds': hbonds,\n",
    "        'salt_bridges': salt_bridges,\n",
    "        'buried_area': buried_area,\n",
    "        'min_distance': min_distance,\n",
    "        'hydrophobic_interactions': hydrophobic_interactions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate structures\n",
    "\n",
    "results = []\n",
    "\n",
    "for folder, structureDict in pdb_structures.items():\n",
    "    print(f\"Processing folder {folder}\")\n",
    "    for structure_name, structureArray in structureDict.items():\n",
    "        print(f\"\\t{structure_name}\")\n",
    "        for file_name, structure in structureArray.items():\n",
    "            results.append(evaluate_structure(file_name, structure))\n",
    "        break\n",
    "    break\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "print(\"---Finished---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Process, Queue, freeze_support\n",
    "import queue\n",
    "print(\"Number of cpu : \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing_libary\n",
    "from multiprocessing import Queue\n",
    "\n",
    "tasks_queued = Queue()\n",
    "tasks_finished = Queue()\n",
    "for folder, structureDict in pdb_structures.items():\n",
    "    for structure_name, structureArray in structureDict.items():\n",
    "        for file_name, structure in structureArray.items():\n",
    "            tasks_queued.put([structure_name, file_name, structure])\n",
    "        break\n",
    "    break\n",
    "\n",
    "multiprocessing_libary.runQueue(tasks_queued, tasks_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "while not tasks_finished.empty():\n",
    "    results.append(tasks_finished.get())\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "tasks_queued = Queue()\n",
    "tasks_finished = Queue()\n",
    "\n",
    "processes = []\n",
    "\n",
    "def run_task():\n",
    "    return True\n",
    "    while True:\n",
    "        try:\n",
    "            task = tasks_queued.get_nowait()\n",
    "        except queue.Empty:\n",
    "            break\n",
    "        else:\n",
    "            tasks_finished.put(evaluate_structure(task[0], task[1]))\n",
    "    return True\n",
    "\n",
    "for folder, structureDict in pdb_structures.items():\n",
    "    for structure_name, structureArray in structureDict.items():\n",
    "        for file_name, structure in structureArray.items():\n",
    "            tasks_queued.put([file_name, structure])\n",
    "        break\n",
    "    break\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    for w in range(1):\n",
    "        p = Process(target=run_task, )\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # completing process\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        print(p.exitcode)\n",
    "\n",
    "    while not tasks_finished.empty():\n",
    "        results.append(tasks_finished.get())\n",
    "\n",
    "    results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder, structureDict in pdb_structures.items():\n",
    "    print(f\"Processing folder {folder}\")\n",
    "    for structure_name, structureArray in structureDict.items():\n",
    "        print(f\"\\t{structure_name}\")\n",
    "        for file_name, structure in structureArray.items():\n",
    "            results.append(evaluate_structure(file_name, structure))\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pdb_structures_path[\"AF_DMI_structures1\"][\"LIG_Clathr_ClatBox_1_1C9I\"][0]\n",
    "structure = pdb_structures[\"AF_DMI_structures1\"][\"LIG_Clathr_ClatBox_1_1C9I\"][0]\n",
    "name = path.stem\n",
    "chains = [c for c in structure[0].get_chains()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
