{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving measurePPI\n",
    "\n",
    "Problem: The ml model clearly sucks (sadly this is the right phrase). Going a step back, maybe it's a good idea to improve the measurements now by including the interface definition and only calculating the properties for interface residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created by Andreas Brilka from a code basis from IMB summmer school\n",
    "# 2024-12-16\n",
    "\n",
    "__version__ = \"1.0.3\"\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "from io import StringIO\n",
    "from multiprocessing import Pool, cpu_count, get_logger\n",
    "import multiprocessing_logging\n",
    "multiprocessing_logging.install_mp_handler()\n",
    "\n",
    "import biotite.structure as struc\n",
    "import biotite.structure.io.pdb as bt_pdb\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.Structure import Structure as BioPy_PDBStructure\n",
    "from Bio.PDB.Model import Model as BioPy_PDBModel\n",
    "from Bio.PDB.PDBExceptions import PDBConstructionException\n",
    "\n",
    "LOGLEVEL_ADDITIONAL_INFO = 19 # The module logs more information like for example the current processed file with this level\n",
    "\n",
    "logger = logging.getLogger(\"measure_PPI\")\n",
    "formatter = logging.Formatter(fmt=\"[%(asctime)s | %(module)s | %(levelname)s] %(message)s\")\n",
    "streamHandler = logging.StreamHandler(sys.stdout)\n",
    "streamHandler.setFormatter(formatter)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(streamHandler)\n",
    "logging.addLevelName(LOGLEVEL_ADDITIONAL_INFO, \"INFO\")\n",
    "\n",
    "_freesasa_ready = False\n",
    "try:\n",
    "    import freesasa\n",
    "    _freesasa_ready = True\n",
    "except ModuleNotFoundError:\n",
    "    logger.warning(\"You don't have freesasa installed. Falling back to biotite\")\n",
    "\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "# This function is included to allow worker threads to output to Jupyter Notebooks as multiprocessing.Pool does not allow to alter sys.stdout of the child processes.\n",
    "# Therefore this function redirects the log output to a buffer, which is transmitted back to the main thread where it is outputed.\n",
    "def _WorkerThreadIni(logLevel:int):\n",
    "    \"\"\"\n",
    "        This function is called in the worker threads by multiprocessing.Pool\n",
    "    \"\"\"\n",
    "    global stdout, logger\n",
    "    stdout = StringIO()\n",
    "    sys.stdout = stdout\n",
    "    streamHandler.setStream(sys.stdout)\n",
    "    logger.setLevel(logLevel)\n",
    "\n",
    "class ProteinStructureWarning(Exception):\n",
    "    def __init__(self, message):            \n",
    "        super().__init__(message)\n",
    "\n",
    "def OpenStructure(path: pathlib.Path, structure_name: str = \"\") -> tuple[BioPy_PDBStructure|None, struc.AtomArray|None]:\n",
    "    \"\"\"\n",
    "        Opens the given structure and returns the Bio.PDB and biotite objects.\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    file_name = path.name\n",
    "    try:\n",
    "        structure_biopy = parser.get_structure(\"structure\", file=path)\n",
    "        structure_biotite = bt_pdb.get_structure(bt_pdb.PDBFile.read(path))\n",
    "    except PDBConstructionException:\n",
    "        logger.warning(f\"Can't parse structure {structure_name} (file {file_name}) using Biopython\")\n",
    "        return (None, None)\n",
    "    except ValueError as ex:\n",
    "        logger.warning(f\"Can't parse structure {structure_name} (file {file_name}) due to the following reason: {ex}\")\n",
    "        return (None, None)\n",
    "    \n",
    "    if structure_biotite.stack_depth() != 1:\n",
    "        logger.warning(f\"Can't parse structure {structure_name} (file {file_name}) because it contains more than one stack\")\n",
    "        return (None, None)\n",
    "    \n",
    "    atomarray_biotite: struc.AtomArray = structure_biotite[0]\n",
    "\n",
    "    chains = [c for c in structure_biopy.get_chains()]\n",
    "    if len(chains) != 2:\n",
    "        logger.warning(f\"Can't parse structure {structure_name} (file {file_name}) because it has not 2 chains\")\n",
    "        return (None, None)\n",
    "    \n",
    "    t1 = time.perf_counter()\n",
    "    logger.debug(f\"Runtime reading structure {structure_name} (file {file_name}): {round((t1-t0)*1000, 1)}ms\")\n",
    "    return (structure_biopy, atomarray_biotite)\n",
    "\n",
    "def calculate_buried_area(structure_biopy:BioPy_PDBStructure):\n",
    "    \"\"\"\n",
    "        Calculates the buried surface area using freesasa which is defined as surface area of the two chains\n",
    "        subtracted from the surface area of the complex.\n",
    "    \"\"\"\n",
    "    ti = time.perf_counter()\n",
    "    chains = [c for c in structure_biopy.get_chains()]\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    chain1 = structure_biopy[0][chains[0].id]\n",
    "    chain2 = structure_biopy[0][chains[1].id]\n",
    "\n",
    "    strucChain1 = BioPy_PDBStructure('structure')\n",
    "    modelChain1 = BioPy_PDBModel(\"1\")\n",
    "    modelChain1.add(chain1)\n",
    "    strucChain1.add(modelChain1)\n",
    "    strucChain2 = BioPy_PDBStructure('structure')\n",
    "    modelChain2 = BioPy_PDBModel(\"1\")\n",
    "    modelChain2.add(chain2)\n",
    "    strucChain2.add(modelChain2)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    fs_pp = freesasa.structureFromBioPDB(structure_biopy)\n",
    "    fs_chain1 = freesasa.structureFromBioPDB(strucChain1)\n",
    "    fs_chain2 = freesasa.structureFromBioPDB(strucChain2)\n",
    "    t2 = time.perf_counter()\n",
    "\n",
    "    area_pp = freesasa.calc(fs_pp).totalArea()\n",
    "    area_chain1 = freesasa.calc(fs_chain1).totalArea()\n",
    "    area_chain2 = freesasa.calc(fs_chain2).totalArea()\n",
    "    tf = time.perf_counter()\n",
    "\n",
    "    buried_area = (area_chain1 + area_chain2 - area_pp)\n",
    "    tf = time.perf_counter()\n",
    "    logger.debug(f\"Sasa values: Chain 1 = {round(area_chain1, 3)}, Chain 2 = {round(area_chain2, 3)}, Total = {round(area_pp, 3)}\")\n",
    "    logger.debug(f\"Runtime calculate_buried_area: {round((tf-ti)*1000, 1)}ms ({round((t1-ti)*1000, 1)}ms model buiilding, {round((t2-t1)*1000, 1)}ms loading, {round((tf-t2)*1000, 1)}ms sasa calc)\")\n",
    "    return round(buried_area, 3)\n",
    "\n",
    "def calculate_buried_area_biotite(atomarray_biotite:struc.AtomArray, chain1:struc.AtomArray, chain2:struc.AtomArray, probe_radius:float=1.4):\n",
    "    \"\"\"\n",
    "        Calculates the buried surface area using biotite which is defined as surface area of the two chains\n",
    "        subtracted from the surface area of the complex.\n",
    "    \"\"\"\n",
    "    ti = time.perf_counter()\n",
    "\n",
    "    sasa12 = np.sum([s for s in struc.sasa(atomarray_biotite, probe_radius=probe_radius) if math.isfinite(s)])\n",
    "    sasa1 = np.sum([s for s in struc.sasa(chain1, probe_radius=probe_radius) if math.isfinite(s)])\n",
    "    sasa2 = np.sum([s for s in struc.sasa(chain2, probe_radius=probe_radius) if math.isfinite(s)])\n",
    "\n",
    "    logger.debug(f\"Sasa values: Chain 1 = {round(sasa1, 3)}, Chain 2 = {round(sasa2, 3)}, Total = {round(sasa12, 3)}\")\n",
    "    buried_area = (sasa1 + sasa2 - sasa12)\n",
    "    tf = time.perf_counter()\n",
    "    logger.debug(f\"Runtime calculate_buried_area: {round((tf-ti)*1000, 1)}ms \")\n",
    "    return round(buried_area, 3)\n",
    "\n",
    "\n",
    "def calculate_min_distance(atomarray_biotite:struc.AtomArray, cutoff:float=5.0, max_cutoff:float = 15.0):\n",
    "    \"\"\"\n",
    "        Calculates the minimum distance [Angstrom] between the two chains of a protein complex using biotite.\n",
    "        The minimum distance is defined as the distance between the backbone (CA atoms) if is subceeds\n",
    "        the cutoff value. For distances above cutoff the algorithm reports NaN\n",
    "\n",
    "        You may whish to apply the cutoff value not for the backbone only but for all atoms of the residue.\n",
    "        For this, set the max_cutoff [Angstrom] to something above cutoff (for example twice) and this function\n",
    "        will report distances above cutoff if a) at least one pair of atoms in the two residues has a distance\n",
    "        below cutoff and b) the backbone distance is still below max_cutoff.\n",
    "        This will require MUCH more computational power and should therefore only be enabled if necessary.\n",
    "    \"\"\"\n",
    "    ti = time.perf_counter()\n",
    "    chains = struc.get_chains(atomarray_biotite)\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    chain1 = atomarray_biotite[atomarray_biotite.chain_id == chains[0]]\n",
    "    chain2 = atomarray_biotite[atomarray_biotite.chain_id == chains[1]]\n",
    "\n",
    "    chain1_backbone = chain1[chain1.atom_name == \"CA\"]\n",
    "    chain2_backbone = chain2[chain2.atom_name == \"CA\"]\n",
    "    \n",
    "    min_distance = float(\"inf\")\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    # max_cutoff is implemented to mimic the same behaviour as the ISS code which used pymol.\n",
    "\n",
    "    for ca1 in chain1_backbone:\n",
    "        for ca2 in chain2_backbone:\n",
    "            if (dist := struc.distance(ca1, ca2)) < cutoff:\n",
    "                min_distance = min(min_distance, dist)\n",
    "                continue\n",
    "            elif dist <= max_cutoff and dist < min_distance: # If max_cutoff is set, check the individual atoms\n",
    "                for a1 in chain1[chain1.res_id == ca1.res_id]:\n",
    "                    for a2 in chain2[chain2.res_id == ca2.res_id]:\n",
    "                        if struc.distance(a1, a2) <= cutoff:\n",
    "                            break\n",
    "                    else: # Runs after loop finished normally\n",
    "                        continue\n",
    "                    break # This only runs if there is a break in the inner loop because of previous continue statement\n",
    "                else:\n",
    "                    # Only calculate min_distance if there is the atom wise distance of the residues is below cutoff\n",
    "                    continue\n",
    "                min_distance = min(min_distance, dist)\n",
    "\n",
    "    tf = time.perf_counter()\n",
    "    logger.debug(f\"Runtime calculate_min_distance: {round((tf-ti)*1000, 1)}ms ({round((t1-ti)*1000, 1)}ms generating chains, {round((tf-t1)*1000, 1)}ms calculating distance)\")\n",
    "    \n",
    "    return round(float(min_distance), 3) if math.isfinite(min_distance) else float('NaN')\n",
    "\n",
    "def calculate_hbonds(atomarray_biotite:struc.AtomArray):\n",
    "    \"\"\"\n",
    "        Calculates the number of hbonds between two chains of a protein complex using biotites AtomArray\n",
    "    \"\"\"\n",
    "    ti = time.perf_counter()\n",
    "    chains = struc.get_chains(atomarray_biotite)\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    chain1_mask = atomarray_biotite.chain_id == chains[0]\n",
    "    chain2_mask = atomarray_biotite.chain_id == chains[1]\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    bond_list = struc.bonds.connect_via_distances(atomarray_biotite)\n",
    "    atomarray_biotite.bonds = bond_list\n",
    "\n",
    "    t2 = time.perf_counter()\n",
    "\n",
    "    triplets = struc.hbond(atomarray_biotite, selection1=chain1_mask, selection2=chain2_mask)\n",
    "    tf = time.perf_counter()\n",
    "    logger.debug(f\"Runtime calculate_hbonds: {round((tf-ti)*1000, 1)}ms ({round((t1-ti)*1000, 1)}ms generating chains, {round((t2-t1)*1000, 1)}ms bond list, {round((tf-t2)*1000, 1)}ms hbonds)\")\n",
    "    \n",
    "    return triplets.shape[0]\n",
    "\n",
    "\n",
    "def calculate_saltbridges(structure_biopy:BioPy_PDBStructure, cutoff:float=4.0):\n",
    "    \"\"\"\n",
    "        Calculates the number of saltbridges between the two chains of a protein complex using biopython.\n",
    "        Saltbridges are defined as a interaction between an acidic residue (ASP, GLU) with a basic residue \n",
    "        (ARG, LYS) and found if the distance between the oxygen and nitrogen atoms is below cutoff [Angstrom]\n",
    "    \"\"\"\n",
    "    ti = time.perf_counter()\n",
    "    chains = [c for c in structure_biopy.get_chains()]\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    chain1 = structure_biopy[0][chains[0].id]\n",
    "    chain2 = structure_biopy[0][chains[1].id]\n",
    "\n",
    "    saltBridges_ac = {\"ASP\":\"a\", \"GLU\":\"a\", \"ARG\":\"b\", \"LYS\":\"b\"} # a: Acidic, b: Basic\n",
    "    saltBridges_atoms = ['OD1', 'OD2', 'OE1', 'OE2', 'NH1', 'NH2', 'NE', 'NZ'] # 0,1: ASP, 2,3: GLU, 4,5,6: ARG, 7: LYS\n",
    "\n",
    "    salt_bridges = 0\n",
    "\n",
    "    for res1 in chain1:\n",
    "        if res1.resname not in saltBridges_ac.keys():\n",
    "            continue\n",
    "        for res2 in chain2:\n",
    "            if res2.resname not in saltBridges_ac.keys():\n",
    "                continue\n",
    "            if saltBridges_ac[res1.resname] == saltBridges_ac[res2.resname]:\n",
    "                continue\n",
    "            for atom1 in [a for a in res1 if a.id in saltBridges_atoms]:\n",
    "                for atom2 in [a for a in res2 if a.id in saltBridges_atoms]:\n",
    "                    distance = atom1 - atom2\n",
    "                    if distance <= cutoff:\n",
    "                        salt_bridges += 1\n",
    "    tf = time.perf_counter()\n",
    "    logger.debug(f\"Runtime calculate_saltbridges: {round((tf-ti)*1000, 1)}ms\")\n",
    "    \n",
    "    return salt_bridges\n",
    "\n",
    "def calculate_hydrophobic_interactions(structure_biopy:BioPy_PDBStructure, cutoff:float=5.0):\n",
    "    \"\"\"\n",
    "        Calculates the number of hydrophobic interactions between two chains of a protein complex using biopython.\n",
    "        Hydrophobic interactions are defined if the C atoms are below the cutoff value [Angstrom] of the following\n",
    "        residues: ALA, VAL, LEU, ILE, MET, PHE, PRO, TRP, GLY\n",
    "    \"\"\"\n",
    "    ti = time.perf_counter()\n",
    "    chains = [c for c in structure_biopy.get_chains()]\n",
    "    assert len(chains) == 2\n",
    "\n",
    "    chain1 = structure_biopy[0][chains[0].id]\n",
    "    chain2 = structure_biopy[0][chains[1].id]\n",
    "\n",
    "    hydrophobic_interactions = 0\n",
    "\n",
    "    hydrophobic_residues = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'PRO', 'TRP', 'GLY'}\n",
    "\n",
    "    # Compare each hydrophobic residue in chain1 with each hydrophobic residue in chain2\n",
    "    for res1 in [r for r in chain1 if r.resname in hydrophobic_residues]:\n",
    "        for atom1 in [a for a in res1 if a.element == 'C']:\n",
    "            for res2 in [r for r in chain2 if r.resname in hydrophobic_residues]:\n",
    "                for atom2 in [a for a in res2 if a.element == 'C']:\n",
    "                    distance = atom1 - atom2\n",
    "                    if distance <= cutoff:\n",
    "                        hydrophobic_interactions += 1\n",
    "\n",
    "    tf = time.perf_counter()\n",
    "    logger.debug(f\"Runtime calculate_hydrophobic_interactions: {round((tf-ti)*1000, 1)}ms\")\n",
    "    \n",
    "    return hydrophobic_interactions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def EvaluateStructure(path: pathlib.Path, structure_name: str = \"\") -> dict|None:\n",
    "    \"\"\"\n",
    "        Measures the pdb file given by path\n",
    "    \"\"\"\n",
    "    ti = time.perf_counter()\n",
    "    file_name = path.name\n",
    "    structure_biopy, atomarray_biotite = OpenStructure(path, structure_name)\n",
    "    if structure_biopy is None or atomarray_biotite is None: raise ProteinStructureWarning(f\"The strucuture {structure_name} (file {path.name}) can't be opened\")\n",
    "\n",
    "    buried_area = calculate_buried_area(structure_biopy) if _freesasa_ready else calculate_buried_area_biotite(atomarray_biotite)\n",
    "    hbonds = calculate_hbonds(atomarray_biotite)\n",
    "    min_distance = calculate_min_distance(atomarray_biotite)\n",
    "    salt_bridges = calculate_saltbridges(structure_biopy)\n",
    "    hydrophobic_interactions = calculate_hydrophobic_interactions(structure_biopy)\n",
    "\n",
    "    tf = time.perf_counter()\n",
    "    logger.log(level=LOGLEVEL_ADDITIONAL_INFO, msg=f\"parsed {structure_name} (file {file_name}) in {round((tf-ti), 3)}s\")\n",
    "    return {\n",
    "        'structure_name': structure_name,\n",
    "        'file': file_name,\n",
    "        'hbonds': hbonds,\n",
    "        'salt_bridges': salt_bridges,\n",
    "        'buried_area': buried_area,\n",
    "        'min_distance': min_distance,\n",
    "        'hydrophobic_interactions': hydrophobic_interactions\n",
    "    }\n",
    "\n",
    "def WalkFolder(basePath: str, \n",
    "               pathObj:dict[str, dict[str, pathlib.Path]]={},\n",
    "               structures: None|str|list[str] = None,\n",
    "               files: None|bool|str|list[str] = None\n",
    "               ) -> dict[str, dict[str, pathlib.Path]]:\n",
    "    \"\"\"\n",
    "        Add the path basePath/structure/file.pdb to the pathObj provided (or create a new one if omitted).\n",
    "        If files and/or structures are None, search inside the directory for all pdb files.\n",
    "        Returns:\n",
    "            pathObj: dict[name:str, tuple[path: pathlib.Path, structure_name: str]]\n",
    "    \"\"\"\n",
    "    structures_count = 0\n",
    "    basePath = pathlib.Path(basePath).absolute()\n",
    "    if not basePath.is_dir():\n",
    "        raise ValueError(\"The given basePath is not a valid directory\")\n",
    "    \n",
    "    if structures is None:\n",
    "        structures: list[pathlib.Path] = [p for p in basePath.iterdir()]\n",
    "    elif isinstance(structures, str):\n",
    "        structures: list[pathlib.Path] = [basePath / structures]\n",
    "    elif isinstance(structures, list):\n",
    "        structures: list[pathlib.Path] = [basePath / p for p in structures]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid argument for structures\")\n",
    "\n",
    "    for structure in structures:\n",
    "        if not structure.exists():\n",
    "            raise ValueError(f\"The structure {structure} does not point to a valid path\")\n",
    "        structure_name = str(structure.name)\n",
    "        if structure.is_file():\n",
    "            if structure.suffix.lower() == \".pdb\":\n",
    "                structure_name = str(structure.stem)\n",
    "                if structure_name in pathObj.keys():\n",
    "                    raise ValueError(f\"Duplicate structure and file {structure}\")\n",
    "                pathObj[structure_name] = (structure.absolute(), structure_name)\n",
    "                structures_count += 1\n",
    "            continue\n",
    "\n",
    "        if files is None:\n",
    "            filesF: list[pathlib.Path] = [f for f in structure.iterdir() if f.is_file()]\n",
    "        elif isinstance(files, str):\n",
    "            filesF: list[pathlib.Path] = [structure / f\"{files}.pdb\"]\n",
    "        elif isinstance(files, list):\n",
    "            filesF: list[pathlib.Path] = [structure / f\"{f}.pdb\" for f in files]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid argument for files\")\n",
    "        \n",
    "        for file in filesF:\n",
    "            if not file.exists() or not file.is_file():\n",
    "                raise ValueError(f\"{structure}/{file} does not point to a valid file\")\n",
    "            if not file.suffix.lower() == \".pdb\":\n",
    "                continue\n",
    "            file_name = file.stem\n",
    "            name = f\"{structure_name}-{file_name}\"\n",
    "            if name in pathObj.keys():\n",
    "                raise ValueError(f\"Duplicate structure and file {structure}/{file_name}.pdb\")\n",
    "            pathObj[name] = (file.absolute(), structure_name)\n",
    "            structures_count += 1\n",
    "    logger.info(f\"Found {structures_count} structures\")\n",
    "    return pathObj\n",
    "\n",
    "\n",
    "# This function is called from the main processes with a pathObj\n",
    "def _run_task(args) -> tuple[dict|None, str]:\n",
    "    \"\"\"\n",
    "        Helper function called from the main process using multiprocessing.Pool and pool.imap_unordered.\n",
    "        Returns a tuple. The first value is either or a dict containing the measurement parameters or None on a error, while the second value\n",
    "        is the output of the logging function.\n",
    "    \"\"\"\n",
    "    path, structure_name = args\n",
    "    try:\n",
    "        r = EvaluateStructure(path, structure_name)\n",
    "    except ProteinStructureWarning as ex:\n",
    "        logger.warning(str(ex))\n",
    "        r = None\n",
    "    output = stdout.getvalue().strip(\"\\n\")\n",
    "    return (r, output)\n",
    "\n",
    "def Run(pathObj: list[tuple[pathlib.Path, str]], num_threads=None) -> pd.DataFrame|None:\n",
    "    \"\"\"\n",
    "        Measures the given paths and returns the result as pandas Dataframe.\n",
    "        pathObj is a list of tuples of (path_to_pdf: pathlib.Path, structure_name: str)\n",
    "        [The structurename is used for the output as filenames often are not unique]\n",
    "    \"\"\"\n",
    "\n",
    "    if len(pathObj) == 0:\n",
    "        logger.warning(f\"You provided an empty pathObj\")\n",
    "        return\n",
    "    logger.info(f\"Started Taskpool of {num_threads} processes for {len(pathObj)} files\")\n",
    "    t0 = time.perf_counter()\n",
    "    with Pool(initializer=_WorkerThreadIni, initargs=[logger.level], processes=(num_threads if num_threads is not None else cpu_count())) as p:\n",
    "        results = []\n",
    "        _ti = t0\n",
    "        _ti_n = 0\n",
    "        for i, rmsg in enumerate(p.imap_unordered(_run_task, pathObj)):\n",
    "            r, output = rmsg\n",
    "            if len(output) > 0:\n",
    "                print(output)\n",
    "            _ti_n += 1\n",
    "            if time.perf_counter() - _ti > 5:\n",
    "                _speed = ((time.perf_counter() - _ti)/_ti_n)**-1 if _ti_n > 0 else 0\n",
    "                _speed_avg = ((time.perf_counter() - t0)/i)**-1 if i > 0 else 0\n",
    "                _eta = (len(pathObj) - i)/_speed_avg if _speed_avg != 0 else -1\n",
    "                _ti = time.perf_counter()\n",
    "                _ti_n = 0\n",
    "                logger.info(f\"{int(100*i/len(pathObj))}% - ETA {str(datetime.timedelta(seconds=int(_eta))) if _eta >= 0 else '?'} | current speed {round(_speed, 3)} s⁻¹ | average speed {round(_speed_avg, 3)} s⁻¹\")\n",
    "            if r is not None:\n",
    "                results.append(r)\n",
    "    _speed_avg = ((time.perf_counter() - t0)/len(pathObj))**-1\n",
    "    num_errors = len(pathObj) - len(results)\n",
    "    logger.info(f\"Finished processing {len(pathObj)} objects{f' ({num_errors} objects produced an error)' if num_errors > 0 else ''} in {str(datetime.timedelta(seconds=int(time.perf_counter() - t0)))} | average speed {round(_speed_avg, 3)} s⁻¹\")\n",
    "    if len(results) == 0:\n",
    "        return None\n",
    "    return pd.DataFrame(results).sort_values([\"structure_name\", \"file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_prediction_results = Path(\"../ressources/AF_predictions/AF_prediction_randomized_DMI_results.xlsx\").resolve()\n",
    "AF_prediction_metrics = Path(\"../ressources/AF_predictions/AF_metrics_all_structures.tsv\").resolve()\n",
    "AF_DMI_structures_folders = [Path(\"../ressources/AF_DMI_structures\").resolve() / p for p in ['AF_DMI_structures1', 'AF_DMI_structures2', 'AF_DMI_structures3', \"AF_DMI_mutated_structures\"]]\n",
    "AF_DDI_structures_path = Path(\"../ressources/AF_DDI_structures\").resolve()\n",
    "solved_DMI_structures_path = Path(\"../ressources/DMI_solved_structures_hydrogens\").resolve()\n",
    "solved_DDI_structures_path = Path(\"../ressources/DDI_solved_structures_hydrogens\").resolve()\n",
    "\n",
    "for p in [AF_prediction_results, AF_prediction_metrics, AF_DDI_structures_path, solved_DMI_structures_path, solved_DDI_structures_path] + AF_DMI_structures_folders:\n",
    "    if not p.exists():\n",
    "        print(f\"{p} does not point to a valid path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-27 15:12:25,438 | 3073387823 | DEBUG] Runtime reading structure LIG_NRP_CendR_1_2ORZ (file ranked_0.pdb): 28.3ms\n"
     ]
    }
   ],
   "source": [
    "#Loading sample structure\n",
    "sampleStructure_name = \"LIG_NRP_CendR_1_2ORZ\"\n",
    "sampleStructure_path = AF_DMI_structures_folders[1] / sampleStructure_name / \"ranked_0.pdb\"\n",
    "structure_biopy, atomarray_biotite = OpenStructure(sampleStructure_path, sampleStructure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwatch\n",
    "from typing import Self\n",
    "import numpy as np\n",
    "\n",
    "class Stopwatch:\n",
    "    \"\"\"\n",
    "        A class to measure performance of many steps with as less code as possible. After creating a Stopwatch, simply call start() and stop() and get the runtime\n",
    "        via the runtime property. Set laps by calling lap(name) and provide a subwatch by calling lap(name, stopwatch) to further detail the runtime in this lap.\n",
    "        To display the times, call to_string() or have a look at MultiStopwatch, which can average over a list of stopwatches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._times: dict[str, float] = {} # Timestamps of starting and stoping the loop as well as of the laps.\n",
    "        self._tstopwatches: dict[str, Self] = {} # Stopwatches, that further detail a lap\n",
    "\n",
    "    @property\n",
    "    def runtime(self) -> float:\n",
    "        \"\"\" The total runtime (in seconds) of this stopwatch or np.inf if not started or stopped yet \"\"\"\n",
    "        if \"_initial\" not in self._times.keys() or \"_final\" not in self._times.keys():\n",
    "            return np.inf\n",
    "        return self._times[\"_final\"] - self._times[\"_initial\"]\n",
    "        \n",
    "    @property\n",
    "    def runtime_laps(self) -> dict[str, float]:\n",
    "        \"\"\" The runtime of the laps as a dictionary \"\"\"\n",
    "        ks, vs = list(self._times.keys()), list(self._times.values())\n",
    "        return {k: (t1-t0) for (k, t0, t1) in zip(ks[1:-1], vs[0:-2], vs[1:-1])}\n",
    "    \n",
    "    @property\n",
    "    def times_stopwatches(self) -> dict[str|Self]:\n",
    "        \"\"\" Dictionary of stopwatches assoiated to a lap \"\"\"\n",
    "        return self._tstopwatches\n",
    "        \n",
    "    def lap(self, name:str, stopwatch:Self|None=None) -> Self:\n",
    "        \"\"\"\n",
    "            Create a lap in the current stopwatch of the given name. Supports associating the lap with a substopwatch which further details the runtime of this step\n",
    "        \"\"\"\n",
    "        if \"_initial\" not in self._times.keys(): raise RuntimeError(\"The stopwatch must first be started\")\n",
    "        if name == \"_final\" or name==\"_initial\": raise KeyError(f\"'{name}' is an invalid name\")\n",
    "        if name in self._times.keys(): raise KeyError(f\"Duplicate key {name}\")\n",
    "        self._times[name] = time.perf_counter()\n",
    "        if stopwatch is not None:\n",
    "            self._tstopwatches[name] = stopwatch\n",
    "        return self\n",
    "\n",
    "    def start(self) -> Self:\n",
    "        \"\"\" Start the stopwatch. Note that a stopwatch can only be started once \"\"\"\n",
    "        if \"_initial\" in self._times.keys(): return self\n",
    "        self._times[\"_initial\"] = time.perf_counter()\n",
    "        return self\n",
    "    \n",
    "    def stop(self) -> Self:\n",
    "        \"\"\" Stop the stopwatch (and all it's lap stopwatches). Note that a stopwatch can only be stoped once once it has been started \"\"\"\n",
    "        if \"_initial\" not in self._times.keys(): return self\n",
    "        for c in self._tstopwatches.values():\n",
    "            c.stop()\n",
    "        if \"_final\" not in self._times.keys():\n",
    "            self._times[\"_final\"] = time.perf_counter()\n",
    "        return self\n",
    "    \n",
    "    def _format_tdelta_float(tdelta_float: float, unit=True) -> str:\n",
    "        \"\"\" Helper function to format a time delta to a string \"\"\"\n",
    "        if tdelta_float == np.inf:\n",
    "            return f\"running\"\n",
    "        if tdelta_float < 0:\n",
    "            raise ValueError(f\"A timedelta must not be negative\")\n",
    "        elif np.abs(tdelta_float) <= 1e-3:\n",
    "            return f\"{round(1e6*tdelta_float, 1)}{' µs' if unit else ''}\" \n",
    "        elif np.abs(tdelta_float) <= 1.0:\n",
    "            return f\"{round(1e3*tdelta_float, 1)}{' ms' if unit else ''}\" \n",
    "        elif np.abs(tdelta_float) <= 10.0:\n",
    "            return f\"{round(tdelta_float, 2)}{' s' if unit else ''}\"  \n",
    "        return str(datetime.timedelta(seconds=tdelta_float))\n",
    "    \n",
    "    def to_string(self, print_=True, max_level:int=3, level:int=0) -> str|None:\n",
    "        \"\"\"\n",
    "            Display the stopwatch as a string. Example output:\n",
    "\n",
    "            Total Runtime: 0:00:14\n",
    "                Step 1: 34,5 ms\n",
    "                Step 2: 0:00:12\n",
    "                    Substep 1: 292.3 µs\n",
    "                    Substep 2: 0:00:11\n",
    "                Step 3: 2.45 s\n",
    "\n",
    "            IMPORTANT: Do not change the level parameter as it is for internal use only\n",
    "        \"\"\"\n",
    "        returnStr = []\n",
    "        if level == 0:\n",
    "            returnStr.append(f\"Total Runtime: {Stopwatch._format_tdelta_float(self.runtime)}\")\n",
    "        if level < max_level:\n",
    "            for name, rtime in self.runtime_laps.items():\n",
    "                returnStr.append(f\"{'\\t'*(level+1)}{name}: {Stopwatch._format_tdelta_float(rtime)}\")\n",
    "                if name in self._tstopwatches.keys():\n",
    "                    returnStr.extend(self._tstopwatches[name].to_string(max_level=max_level, level=(level+1)))\n",
    "        if level == 0:\n",
    "            if print_: \n",
    "                print('\\n'.join(returnStr))\n",
    "                return \n",
    "            return '\\n'.join(returnStr)\n",
    "        return returnStr\n",
    "\n",
    "class MultiStopwatch:\n",
    "    \"\"\"\n",
    "        A class to hold a list of stopwatches and create average runtime statistics from them. Supports nested laps as provided by the Stopwatch class\n",
    "\n",
    "        The MultiStopwatch can measure the total runtime by calling start() and stop(), but it isn't needed for a valid output. To add a child, call add_child(stopwatch)\n",
    "        or view them by accessing the childs property. Call to_string(max_level) to display an average output of all it's childs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._starttime: float|None = None\n",
    "        self._stoptime: float|None = None\n",
    "        self._childs: list[Stopwatch] = []\n",
    "\n",
    "    def start(self) -> Self:\n",
    "        \"\"\" Start the Stopwatch. Note that a stopwatch can only be started once \"\"\"\n",
    "        if self._starttime is not None: return self\n",
    "        self._starttime = time.perf_counter()\n",
    "        return self\n",
    "    \n",
    "    def stop(self) -> Self:\n",
    "        \"\"\" Stop the stopwatch and all it's childrens. Note that a stopwatch can only be stoped once\"\"\"\n",
    "        if self._starttime is None: return self\n",
    "        for c in self._childs:\n",
    "            c.stop()\n",
    "        if self._stoptime is None: \n",
    "            self._stoptime = time.perf_counter()\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def runtime(self) -> float:\n",
    "        \"\"\" The total runtime of this stopwatch or np.inf if not started or stopped yet \"\"\"\n",
    "        if self._starttime is None or self._stoptime is None:\n",
    "            return np.inf\n",
    "        return self._stoptime - self._starttime\n",
    "    \n",
    "    def add_child(self, stopwatch:Stopwatch) -> Self:\n",
    "        \"\"\" Add a stopwatch \"\"\"\n",
    "        if not isinstance(stopwatch, Stopwatch): raise TypeError(f\"add_childs needs a Stopwatch, but you provided {type(stopwatch)}\")\n",
    "        self._childs.append(stopwatch)\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def childs(self) -> list[Stopwatch]:\n",
    "        return self._childs\n",
    "    \n",
    "    def to_string(self, print_=True, max_level:int=3) -> str|None:\n",
    "        \"\"\" Display averaged runtime statistics for all it's child stopwatches. Example output: \n",
    "        \n",
    "            Total Runtime: 0:00:14 ± 2.39 s (n=13)\n",
    "                Step 1: 34,5 ms ± 6.5 ms (n=13)\n",
    "                Step 2: 0:00:12 ± 1.35 s (n=13)\n",
    "                    Substep 1: 292.3 µs ± 1.1 ms (n=9)\n",
    "                    Substep 2: 0:00:11 ± 982.3 ms (n=7)\n",
    "                Step 3: 2.45 s ± 162 ms (n=2)\n",
    "        \"\"\"\n",
    "\n",
    "        def _deref(stopwatches:list[Stopwatch], max_level=max_level, level=0):\n",
    "            returnStr = []\n",
    "\n",
    "            runtimesDict = {} # Dictionary of all runtimes per lap name in the list of stopwatches\n",
    "            lapStopwatchesDict = {} # Dictionary of all lap stopwatches per lap name in the list of stopwatches\n",
    "            for s in stopwatches:\n",
    "                for k,v in s.runtime_laps.items():\n",
    "                    runtimesDict.setdefault(k, []).append(v)\n",
    "                for k,v in s.times_stopwatches.items():\n",
    "                    lapStopwatchesDict.setdefault(k, []).append(v)\n",
    "            for k, runtimes in runtimesDict.items():\n",
    "                if len(runtimes) == 0:\n",
    "                    continue\n",
    "                mean = np.mean(runtimes)\n",
    "                std = np.std(runtimes)\n",
    "                returnStr.append(f\"{'\\t'*level}{k}: {Stopwatch._format_tdelta_float(mean)} ± {Stopwatch._format_tdelta_float(std)} (n={len(runtimes)})\")\n",
    "                if k in lapStopwatchesDict.keys() and level < max_level:\n",
    "                    returnStr.extend(_deref(lapStopwatchesDict[k], max_level=max_level, level=(level+1)))\n",
    "            return returnStr\n",
    "        \n",
    "        returnStr = [f\"Total Runtime: {Stopwatch._format_tdelta_float(self.runtime)} (n={len(self._childs)})\"]\n",
    "        returnStr.extend(_deref(self._childs, max_level=max_level, level=1))\n",
    "        if print_: \n",
    "            print('\\n'.join(returnStr))\n",
    "            return \n",
    "        return '\\n'.join(returnStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from Bio.PDB.Atom import Atom as BioPy_Atom\n",
    "\n",
    "class ProteinStructureWarning(Exception):\n",
    "    def __init__(self, message):            \n",
    "        super().__init__(message)\n",
    "\n",
    "def get_distance_matrix(structure_biopy:BioPy_PDBStructure) -> tuple[np.ndarray, list[BioPy_Atom], list[BioPy_Atom]]:\n",
    "    stopwatch = Stopwatch().start()\n",
    "    chains = [c for c in structure_biopy.get_chains()]\n",
    "    if not len(chains) == 2: raise ProteinStructureWarning(f\"The protein needs to have 2 chains but it has {len(chains)}\")\n",
    "    chain1 = structure_biopy[0][chains[0].id]\n",
    "    chain2 = structure_biopy[0][chains[1].id]\n",
    "    \n",
    "\n",
    "    chain1_atoms = np.array([a for a in chain1.get_atoms()])\n",
    "    chain2_atoms = np.array([a for a in chain2.get_atoms()])\n",
    "    chain1_coords = [a.coord for a in chain1_atoms]\n",
    "    chain2_coords = [a.coord for a in chain2_atoms]\n",
    "    stopwatch.lap(\"Parsing the chains and atom arrays\")\n",
    "\n",
    "    distance_matrix = pairwise_distances(chain1_coords,chain2_coords)\n",
    "    stopwatch.lap(\"Distance Matrix\")\n",
    "\n",
    "    return (distance_matrix, chain1_atoms, chain2_atoms, stopwatch.stop())\n",
    "\n",
    "def get_interface(distance_matrix: np.ndarray, chain1_atoms: list[BioPy_Atom], chain2_atoms: list[BioPy_Atom], cutoff=5.0):\n",
    "    stopwatch = Stopwatch().start()\n",
    "    pair_dist = np.argwhere(distance_matrix <= cutoff) # List of matrix indices where distance is below cutoff\n",
    "    intf1_atoms = set(chain1_atoms[pair_dist[:, 0]]) # Set of the chain1 atoms with an atom from chain2 closer than cutoff distance\n",
    "    intf2_atoms = set(chain2_atoms[pair_dist[:, 1]])\n",
    "    stopwatch.lap(\"Interface atoms\")\n",
    "\n",
    "    # List of backbone atoms in the interface\n",
    "    intf1_backbone = [a for a in intf1_atoms if a.name == \"CA\" and a in intf1_atoms]\n",
    "    intf2_backbone = [a for a in intf2_atoms if a.name == \"CA\" and a in intf2_atoms]\n",
    "    stopwatch.lap(\"Interface backbone\")\n",
    "\n",
    "    intf1_residues = [a.parent for a in intf1_backbone]\n",
    "    intf2_residues = [a.parent for a in intf2_backbone]\n",
    "\n",
    "    # A list for each chain combined to a tuple with the indices of the interface residues. Example : ([23, 445, 470], [26]) \n",
    "    backbone_indices_tuple = ([i for i,a in enumerate(chain1_atoms) if a in intf1_backbone], [i for i,a in enumerate(chain2_atoms) if a in intf2_backbone]) \n",
    "\n",
    "    # The distance matrix sliced to only the interface backbone atoms. So shape is (len(intf1_backbone), len(intf2_backbone))\n",
    "    local_dist_matrix = distance_matrix[backbone_indices_tuple[0], :][:, backbone_indices_tuple[1]]\n",
    "\n",
    "    stopwatch.lap(\"local distance matrix\")\n",
    "\n",
    "    min_distance = round(np.min(local_dist_matrix), 3)\n",
    "\n",
    "    return (intf1_residues, intf2_residues, min_distance, stopwatch.stop())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Runtime: 162.9 ms\n",
      "\tLoading structure: 22.1 ms\n",
      "\tDistance Matrix: 3.5 ms\n",
      "\t\tParsing the chains and atom arrays: 2.1 ms\n",
      "\t\tDistance Matrix: 1.3 ms\n",
      "\tDefining Interface: 5.2 ms\n",
      "\t\tInterface atoms: 771.8 µs\n",
      "\t\tInterface backbone: 14.6 µs\n",
      "\t\tlocal distance matrix: 4.4 ms\n",
      "\tSurface Area: 78.7 ms\n",
      "\tH-Bonds: 14.5 ms\n",
      "\tInterface Distance: 33.6 ms\n",
      "\tSalt bridges: 626.0 µs\n",
      "\tHydropphobic interactions: 4.7 ms\n"
     ]
    }
   ],
   "source": [
    "def EvaluateStructure(path: pathlib.Path, structure_name: str = \"\") -> tuple[dict|None, Stopwatch] :\n",
    "    \"\"\"\n",
    "        Measures the pdb file given by path\n",
    "    \"\"\"\n",
    "    stopwatch = Stopwatch().start()\n",
    "    file_name = path.name\n",
    "    structure_biopy, atomarray_biotite = OpenStructure(path, structure_name)\n",
    "    stopwatch.lap(\"Loading structure\")\n",
    "    if structure_biopy is None or atomarray_biotite is None: return (None, stopwatch.stop())\n",
    "\n",
    "    distance_matrix, chain1_atoms, chain2_atoms, s_dist_matrix = get_distance_matrix(structure_biopy)\n",
    "    stopwatch.lap(\"Distance Matrix\", s_dist_matrix)\n",
    "    intf1_residues, intf2_residues, min_distance, s_interface = get_interface(distance_matrix, chain1_atoms, chain2_atoms)\n",
    "\n",
    "    stopwatch.lap(\"Defining Interface\", s_interface)\n",
    "\n",
    "    buried_area = calculate_buried_area(structure_biopy) if _freesasa_ready else calculate_buried_area_biotite(atomarray_biotite)\n",
    "    stopwatch.lap(\"Surface Area\")\n",
    "    hbonds = calculate_hbonds(atomarray_biotite)\n",
    "    stopwatch.lap(\"H-Bonds\")\n",
    "    min_distance = calculate_min_distance(atomarray_biotite)\n",
    "    stopwatch.lap(\"Interface Distance\")\n",
    "    salt_bridges = calculate_saltbridges(structure_biopy)\n",
    "    stopwatch.lap(\"Salt bridges\")\n",
    "    hydrophobic_interactions = calculate_hydrophobic_interactions(structure_biopy)\n",
    "    stopwatch.lap(\"Hydropphobic interactions\")\n",
    "\n",
    "    return ({\n",
    "        'structure_name': structure_name,\n",
    "        'file': file_name,\n",
    "        'chainA_intf_res': len(intf1_residues),\n",
    "        'chainB_intf_res': len(intf2_residues),\n",
    "        'interface_distance': min_distance,\n",
    "        'buried_area': buried_area,\n",
    "\n",
    "        'hbonds': hbonds,\n",
    "        'salt_bridges': salt_bridges,\n",
    "        'hydrophobic_interactions': hydrophobic_interactions\n",
    "    }, stopwatch.stop())\n",
    "\n",
    "multiStopwatch = MultiStopwatch().start()\n",
    "result, stopwatch = EvaluateStructure(sampleStructure_path, sampleStructure_name)\n",
    "multiStopwatch.add_child(stopwatch)\n",
    "multiStopwatch.stop()\n",
    "stopwatch.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondList = struc.BondList()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
