{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecaba5d7",
   "metadata": {},
   "source": [
    "# AF metrics: File name parsing, template dependend metrics, \n",
    "Created 04.04.2025 by Andreas B\n",
    "\n",
    "This script takes structure files and creates various metrics with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f983aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes._axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import re\n",
    "import filecmp\n",
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "import pymol\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.Structure import Structure as BioPy_PDBStructure\n",
    "from Bio.PDB.Model import Model as BioPy_PDBModel\n",
    "from Bio.PDB.PDBExceptions import PDBConstructionException\n",
    "parser = PDBParser(QUIET=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "# Path to the parsed AF output. Folder should have the following structure:\n",
    "# DMI\n",
    "#  Benchmark set 1\n",
    "#  Benchmark set 2\n",
    "# DDI\n",
    "#  Benchmark set 1\n",
    "#  Benchmark set 2\n",
    "path_AF = Path(\"../ressources/AF2\").resolve()\n",
    "\n",
    "# Path to the solved structures. Should have two folders: DMI and DDI\n",
    "path_solved = Path(\"../ressources/solved\").resolve()\n",
    "\n",
    "# Mode\n",
    "af_mode: Literal[\"AF2\", \"AF3\"] = \"AF2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the AF data\n",
    "if af_mode == \"AF2\":\n",
    "    dataAF = pd.read_csv(path_AF / \"AF_metrics_all_structures.tsv\", sep=\"\\t\")\n",
    "    # Drop columns to recalculate them\n",
    "    dataAF.drop(columns=[\"RMSD_domain\", \"num_align_atoms_domain\", \"align_score_domain\", \"num_align_resi_domain\", \"RMSD_backbone_peptide\", \"RMSD_all_atom_peptide\", \"known_motif_plddt\", \"DockQ\", \"iRMS\", \"LRMS\", \"Fnonnat\", \"label\"], inplace=True)\n",
    "\n",
    "    # Adding benchmark set column\n",
    "    benchmark_set_replace_dict = {\"1\": \"mutations_DMI\", \"2\" : \"mutations_DMI\", \"approved minimal DDI\": \"known_DDI\", \"known minimal\": \"known_DMI\", \"random minimal\": \"random_DMI\", \"random minimal DDI\": \"random_DDI\"}\n",
    "    dataAF[\"benchmark_set\"] = None\n",
    "    dataAF[\"num_mutations\"] = None\n",
    "\n",
    "    for i, row in dataAF.iterrows():\n",
    "        if row[\"num_mutation_in_motif\"] == \"1\":\n",
    "            dataAF.at[i, \"num_mutations\"] = 1\n",
    "        elif row[\"num_mutation_in_motif\"] == \"2\":\n",
    "            dataAF.at[i, \"num_mutations\"] = 2\n",
    "        benchmark_set = benchmark_set_replace_dict[row[\"num_mutation_in_motif\"]]\n",
    "        dataAF.at[i, \"benchmark_set\"] = benchmark_set\n",
    "    dataAF.drop(columns=[\"num_mutation_in_motif\"], inplace=True)\n",
    "\n",
    "elif af_mode == \"AF3\":\n",
    "    dataAF = pd.read_csv(path_AF / \"AF3_raw_metrics.tsv\", sep=\"\\t\")\n",
    "\n",
    "    benchmark_set_replace_dict = {\"mutations\": \"mutations_DMI\", \"known_minimal\": \"known_DMI\", \"known_DDI\": \"known_DDI\", \"random_minimal\": \"random_DMI\", \"random_DDI\": \"random_DDI\"}\n",
    "\n",
    "    for i, row in dataAF.iterrows():\n",
    "        if row[\"num_mutation_in_motif\"] == \"1\":\n",
    "            dataAF.at[i, \"num_mutations\"] = 1\n",
    "        elif row[\"num_mutation_in_motif\"] == \"2\":\n",
    "            dataAF.at[i, \"num_mutations\"] = 2\n",
    "        benchmark_set = benchmark_set_replace_dict[row[\"num_mutation_in_motif\"]]\n",
    "        dataAF.at[i, \"benchmark_set\"] = benchmark_set\n",
    "\n",
    "display(dataAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in solved structure data\n",
    "\n",
    "dataSolved = pd.DataFrame(columns=[\"set\", \"PDB_id\", \"ddi_pfam_id\", \"path\", \"chainA_id\", \"chainB_id\"])\n",
    "\n",
    "# DMI\n",
    "for structure_file in [p for p in Path(path_solved / \"DMI\").iterdir() if p.is_file() and p.suffix == \".pdb\"]:\n",
    "    pdb_id = structure_file.name.split(\"_\")[0]\n",
    "    dataSolved.loc[len(dataSolved)] = {\"set\" : \"DMI\", \"PDB_id\": pdb_id, \"path\": structure_file.relative_to(path_solved), \"chainA_id\": \"A\", \"chainB_id\": \"B\"}\n",
    "\n",
    "# DDI\n",
    "for structure_file in [p for p in Path(path_solved / \"DDI\").iterdir() if p.is_file() and p.suffix == \".pdb\"]:\n",
    "    ddi_pfam_id = \"_\".join(structure_file.name.split(\"_\")[0:2])\n",
    "    pdb_id = structure_file.name.split(\"_\")[2]\n",
    "    chainA_id = structure_file.name.split(\"_\")[3][0]\n",
    "    chainB_id = structure_file.name.split(\"_\")[3][1]\n",
    "    dataSolved.loc[len(dataSolved)] = {\"set\" : \"DDI\", \"PDB_id\": pdb_id, \"ddi_pfam_id\": ddi_pfam_id, \"path\": structure_file.relative_to(path_solved), \"chainA_id\": chainA_id, \"chainB_id\": chainB_id}\n",
    "\n",
    "display(dataSolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex checks on filename\n",
    "regex_paired_DMI = r\"^([\\w\\-]+)_(\\w{4})$\"\n",
    "regex_random_DMI = r\"^M([\\w\\-]+)_(\\w{4})\\.D([\\w\\-]+)_(\\w{4})$\"\n",
    "regex_mutated_DMI = r\"^([\\w\\-]+)_(\\w{4})_(\\w+)\\.([A-Za-z]+)$\"\n",
    "regex_known_extension_DMI = r\"^([\\w-]+)_((Mmin)|(MFL)|(M[\\d]+_M[\\d]+))_((DFL)|(Dmin)|(D[\\d]+_D[\\d]+))$\"\n",
    "regex_ddi_known = r\"^([^\\W_]+_[^\\W_]+)_(\\w{4})_(\\w+)_resi(\\d+)_resi(\\d+).(\\w+)_resi(\\d+)_resi(\\d+)$\"\n",
    "regex_ddi_random = r\"^D1([^\\W_]+_[^\\W_]+)_(\\w{4}).D2([^\\W_]+_[^\\W_]+)_(\\w{4})$\"\n",
    "\n",
    "\n",
    "dataAF[\"PDB_id\"] = None\n",
    "dataAF[\"ELM_instance\"] = None\n",
    "dataAF[\"ddi_pfam_id\"] = None\n",
    "dataAF[\"PDB_id_random_paired\"] = None\n",
    "dataAF[\"ELM_instance_random_paired\"] = None\n",
    "dataAF[\"ddi_pfam_id_random_paired\"] = None\n",
    "dataAF[\"sequence_initial\"] = None\n",
    "dataAF[\"sequence_mutated\"] = None\n",
    "# known_extensions have not been run. Therefore exclude them here but keep the code for them\n",
    "#dataAF[\"known_extension_motif\"] = None \n",
    "#dataAF[\"known_extension_domain\"] = None\n",
    "dataAF[\"chainA_id\"] = None\n",
    "dataAF[\"chainB_id\"] = None\n",
    "dataAF[\"chainA_start\"] = None\n",
    "dataAF[\"chainA_end\"] = None\n",
    "dataAF[\"chainB_start\"] = None\n",
    "dataAF[\"chainB_end\"] = None\n",
    "\n",
    "for i, row in dataAF.iterrows():\n",
    "    pdb_id, pdb_id_2, elm_instance, elm_instance_2, sequence, sequence_f = None, None, None, None, None, None\n",
    "    known_extensionM, known_extensionD, chain1_letter, chain2_letter, ddi_pfam_id, ddi_pfam_id_random_paired = None, None, None, None, None, None\n",
    "    c1_start, c1_end, c2_start, c2_end = None, None, None, None\n",
    "    if (benchmark_set := row[\"benchmark_set\"]) == \"known_DMI\":\n",
    "        if (r1 := re.search(regex_paired_DMI, row[\"prediction_name\"])) is not None and len(r1.groups()) == 2:\n",
    "            elm_instance = r1.groups()[0]\n",
    "            pdb_id = r1.groups()[1]\n",
    "            chain1_letter, chain2_letter = \"A\", \"B\"\n",
    "    elif benchmark_set == \"random_DMI\":\n",
    "        if (r := re.search(regex_random_DMI, row[\"prediction_name\"])) is not None and len(r.groups()) == 4:\n",
    "            # Contraintuitive, but here before dot is motif and after dot is domain\n",
    "            elm_instance_2 = r.groups()[0]\n",
    "            pdb_id_2 = r.groups()[1]\n",
    "            elm_instance = r.groups()[2]\n",
    "            pdb_id = r.groups()[3]\n",
    "            chain1_letter, chain2_letter = \"A\", \"B\"\n",
    "    elif benchmark_set == \"mutations_DMI\":\n",
    "        if (r := re.search(regex_mutated_DMI, row[\"prediction_name\"])) is not None and len(r.groups()) == 4:\n",
    "            elm_instance = r.groups()[0]\n",
    "            pdb_id = r.groups()[1]\n",
    "            sequence = r.groups()[2]\n",
    "            sequence_f = r.groups()[3]\n",
    "            chain1_letter, chain2_letter = \"A\", \"B\"\n",
    "    #elif benchmark_set == \"known_extension\":\n",
    "    #    if (r := re.search(regex_known_extension_DMI, row[\"prediction_name\"])) is not None and len(r.groups()) == 9:\n",
    "    #        elm_instance = r.groups()[0]\n",
    "    #        known_extensionM = r.groups()[1]\n",
    "    #        known_extensionD = r.groups()[5]\n",
    "    elif benchmark_set == \"known_DDI\":\n",
    "        if (r := re.search(regex_ddi_known, row[\"prediction_name\"])) is not None and len(r.groups()) == 8:\n",
    "            ddi_pfam_id = r.groups()[0]\n",
    "            pdb_id = r.groups()[1]\n",
    "            chain1_letter = r.groups()[2]\n",
    "            c1_start = r.groups()[3]\n",
    "            c1_end = r.groups()[4]\n",
    "            chain2_letter = r.groups()[5]\n",
    "            c2_start = r.groups()[6]\n",
    "            c2_end = r.groups()[7]\n",
    "\n",
    "            if pdb_id != pdb_id.upper():\n",
    "                pdb_id = pdb_id.upper()\n",
    "                new_prediction_name = row[\"prediction_name\"][:r.span(2)[0]] + pdb_id + row[\"prediction_name\"][r.span(2)[1]:]\n",
    "                print(f\"Fixed prediction_name in set {benchmark_set} from {row['prediction_name']} to {new_prediction_name}\")\n",
    "                dataAF.at[i, \"prediction_name\"] = new_prediction_name\n",
    "    elif benchmark_set == \"random_DDI\":\n",
    "        if (r := re.search(regex_ddi_random, row[\"prediction_name\"])) is not None and len(r.groups()) == 4:\n",
    "            ddi_pfam_id = r.groups()[0]\n",
    "            pdb_id = r.groups()[1]   \n",
    "            ddi_pfam_id_random_paired = r.groups()[2]\n",
    "            pdb_id_2 = r.groups()[3]  \n",
    "    else:\n",
    "        raise RuntimeError(f\"Regex failed on {row['pdb_id']}\")\n",
    "    \n",
    "    dataAF.at[i, \"PDB_id\"] =  pdb_id\n",
    "    dataAF.at[i, \"PDB_id_random_paired\"] =  pdb_id_2\n",
    "    dataAF.at[i, \"ELM_instance\"] =  elm_instance\n",
    "    dataAF.at[i, \"ELM_instance_random_paired\"] =  elm_instance_2\n",
    "    dataAF.at[i, \"sequence_initial\"] =  sequence\n",
    "    dataAF.at[i, \"sequence_mutated\"] =  sequence_f\n",
    "    #dataAF.at[i, \"known_extension_motif\"] =  known_extensionM\n",
    "    #dataAF.at[i, \"known_extension_domain\"] =  known_extensionD\n",
    "    dataAF.at[i, \"chainA_id\"] =  chain1_letter\n",
    "    dataAF.at[i, \"chainB_id\"] =  chain2_letter\n",
    "    dataAF.at[i, \"ddi_pfam_id\"] =  ddi_pfam_id\n",
    "    dataAF.at[i, \"ddi_pfam_id_random_paired\"] =  ddi_pfam_id_random_paired\n",
    "    dataAF.at[i, \"chainA_start\"] =  c1_start\n",
    "    dataAF.at[i, \"chainA_end\"] =  c1_end\n",
    "    dataAF.at[i, \"chainB_start\"] =  c2_start\n",
    "    dataAF.at[i, \"chainB_end\"] =  c2_end\n",
    "\n",
    "# The chain ids as well as start and end residues for the random_ddi can be obtained from the random DDI\n",
    "for i, row in dataAF[dataAF[\"benchmark_set\"] == \"random_DDI\"].iterrows():\n",
    "    prediction_name = row[\"prediction_name\"]\n",
    "    pdb_id, pdb_id_2 = row[\"PDB_id\"], row[\"PDB_id_random_paired\"]\n",
    "    ddi_pfam_id, ddi_pfam_id_2 = row[\"ddi_pfam_id\"], row[\"ddi_pfam_id_random_paired\"]\n",
    "    \n",
    "    if len(list((_row1 := dataAF[np.logical_and(dataAF[\"benchmark_set\"] == \"known_DDI\", np.logical_and(dataAF[\"PDB_id\"] == pdb_id, dataAF[\"ddi_pfam_id\"] == ddi_pfam_id))])[\"chainA_id\"])) == 0:\n",
    "        print(f\"Can't find {pdb_id} from {prediction_name} (random_ddi, chain A) in the known_DDI set\")\n",
    "        continue\n",
    "    if len(list((_row2 := dataAF[np.logical_and(dataAF[\"benchmark_set\"] == \"known_DDI\", np.logical_and(dataAF[\"PDB_id\"] == pdb_id_2, dataAF[\"ddi_pfam_id\"] == ddi_pfam_id_2))])[\"chainB_id\"])) == 0:\n",
    "        print(f\"Can't find {pdb_id_2} from {prediction_name} (random_ddi, chain B) in the known_DDI set\")\n",
    "        continue\n",
    "    dataAF.at[i, \"chainA_id\"] = list(_row1[\"chainA_id\"])[0]\n",
    "    dataAF.at[i, \"chainA_start\"] = list(_row1[\"chainA_start\"])[0]\n",
    "    dataAF.at[i, \"chainA_end\"] = list(_row1[\"chainA_end\"])[0]\n",
    "    dataAF.at[i, \"chainB_id\"] =  list(_row2[\"chainB_id\"])[0]\n",
    "    dataAF.at[i, \"chainB_start\"] = list(_row2[\"chainB_start\"])[0]\n",
    "    dataAF.at[i, \"chainB_end\"] = list(_row2[\"chainB_end\"])[0]\n",
    "print(\"\\n\", f\"Rows, where the regex failed\")\n",
    "display(dataAF[dataAF[\"PDB_id\"].isna()])\n",
    "display(dataAF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
